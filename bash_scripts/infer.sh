# bash ./bash_scripts/infer.sh > logs/infer.log 2>&1


CUDA_VISIBLE_DEVICES=0 python inference.py \
    data@data_dict=example \
    +ckpt_dir=ckpt/mmedit \
    +use_best=true \
    # +ckpt_dir=experiments/tta/epoch_81



    # exp_dir=experiments/tts/ljspeech/VaribleLengthAudioDiffusion_24Khz_lr1.5e-4_80epoch \

    # epoch_length=1000 \
    # epochs=100 \
    # train_dataloader.batch_size=12 \
    # val_dataloader.batch_size=12 \
    # model=diffusion_singing \
    # loss@loss_fn=weighted_sum \
    # exp_dir=experiments/tts/ljspeech \
    # optimizer.lr=5e-5 \
    # loss_fn.weights.local_duration_loss=0.0 \
    # trainer.wandb_config.project=singing_popcs \
    # trainer.wandb_config.name=vae_wave_backbone_audioudit_layers_24_dim_1024_loss_diff
    # +trainer.resume_from_checkpoint=experiments/waveform_vae_audioudit_layers_24_dim_1024_diffusion/opencpop/checkpoints/epoch_51
    # ~trainer.wandb_config \